# Projeto de Clusteriza√ß√£o de Dados

Este projeto √© uma solu√ß√£o completa para realizar a clusteriza√ß√£o de dados, desde a ingest√£o e processamento inicial at√© o treinamento e avalia√ß√£o de modelos de machine learning. O sistema √© dividido em dois componentes principais: um m√≥dulo de ingest√£o de dados e um pipeline de treinamento de modelos de clusteriza√ß√£o.

## ‚ú® Funcionalidades

- **M√≥dulo de Ingest√£o de Dados:** Coleta e prepara dados brutos de forma automatizada.
- **Processamento e Limpeza:** Pipelines para validar, limpar e transformar os dados.
- **Engenharia de Features:** Cria√ß√£o e sele√ß√£o de features para otimizar o desempenho dos modelos.
- **Treinamento de Modelos:** Suporte para m√∫ltiplos algoritmos de clusteriza√ß√£o, como K-Means e Gaussian Mixture Models (GMM).
- **Estrutura Modular:** C√≥digo organizado em componentes reutiliz√°veis, facilitando a manuten√ß√£o e a expans√£o.

## üìÇ Estrutura do Projeto

O projeto est√° organizado nos seguintes diret√≥rios principais:

- **`/data_ingestion`**: M√≥dulo respons√°vel pela coleta e armazenamento inicial dos dados. Cont√©m sua pr√≥pria l√≥gica, CLI e configura√ß√µes.
- **`/src`**: Cont√©m o c√≥digo principal da aplica√ß√£o, incluindo os pipelines de processamento, treinamento de modelos e utilit√°rios.
- **`/notebooks`**: Jupyter Notebooks para an√°lise explorat√≥ria, testes e prototipagem.
- **`/main.py`**: Ponto de entrada principal para orquestrar os pipelines do projeto.
- **`/requirements.txt`**: Lista de depend√™ncias Python do projeto.

## üöÄ Como Come√ßar

Siga as instru√ß√µes abaixo para configurar e executar o projeto em seu ambiente local.

### Pr√©-requisitos

- Python 3.9 ou superior
- Git

### Instala√ß√£o

1.  Clone o reposit√≥rio para sua m√°quina local:
    ```bash
    git clone <URL_DO_REPOSITORIO>
    cd <NOME_DO_PROJETO>
    ```

2.  Crie um ambiente virtual e ative-o:
    ```bash
    python -m venv .venv
    source .venv/bin/activate  # No Windows, use: .venv\Scripts\activate
    ```

3.  Instale as depend√™ncias necess√°rias:
    ```bash
    pip install -r requirements.txt
    ```

## üõ†Ô∏è Uso

A execu√ß√£o do projeto √© dividida em duas etapas principais: ingest√£o de dados e treinamento do pipeline.

### 1. Ingest√£o de Dados

O m√≥dulo `data_ingestion` √© respons√°vel por baixar e processar os dados brutos. Ele possui uma interface de linha de comando (CLI) pr√≥pria para iniciar o processo. Para mais detalhes, consulte o `README.md` dentro do diret√≥rio `data_ingestion`.

Para executar a ingest√£o, navegue at√© o diret√≥rio e execute o script principal:
```bash
python data_ingestion/main.py <COMANDOS_DA_CLI>
```

### 2. Pipeline de Treinamento

Ap√≥s a conclus√£o da etapa de ingest√£o, os dados estar√£o prontos para serem processados e utilizados no treinamento dos modelos. O script `main.py` na raiz do projeto orquestra todas as etapas do pipeline principal.

Para executar o pipeline completo (processamento, sele√ß√£o de features e treinamento), execute:
```bash
python main.py
```

## ‚öôÔ∏è Configura√ß√£o

As configura√ß√µes do projeto, como caminhos de arquivos, par√¢metros de modelos e configura√ß√µes de ambiente, podem ser encontradas e modificadas nos seguintes locais:

- **Ingest√£o de Dados:** `data_ingestion/config/`
- **Pipeline Principal:** `src/config/`
